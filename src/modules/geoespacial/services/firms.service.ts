// src/modules/geoespacial/services/firms.service.ts
import { AppDataSource } from '../../../db/data-source'
import env from '../../../config/env'
import { buildFirmsUrls } from '../firms.config'
import { PuntoCalor } from '../entities/punto-calor.entity'
import { AuditoriaEventos } from '../../auditoria/entities/auditoria-eventos.entity'
import { JobRun } from '../../jobs/entities/job-run.entity'

type Row = Record<string, any>

// --- Aliases/normalizaci√≥n de entorno ---
const RADIUS_KM = Number(process.env.FIRMS_RADIUS_KM ?? process.env.FIRMS_BUFFER_KM ?? 25)
const WINDOW_H  = Number(process.env.FIRMS_TIME_WINDOW_HOURS ?? process.env.FIRMS_TIME_WINDOW_H ?? 24)

// --- Helpers de parsing seguros ---
function toNum(x: any) {
  const s = String(x ?? '').trim().replace(/^"(.*)"$/, '$1')
  const n = Number(s)
  return Number.isFinite(n) ? n : NaN
}
function toFloat(x: any) {
  const s = String(x ?? '').trim().replace(/^"(.*)"$/, '$1')
  const n = parseFloat(s)
  return Number.isFinite(n) ? n : NaN
}

// Hash de deduplicaci√≥n por minuto + posici√≥n redondeada (1e-4¬∞)
function hashDedupe(
  fuente: string,
  instrument: string,
  satellite: string,
  acq_date: string,
  acq_time: number,
  lat: number,
  lon: number
) {
  const rlat = Math.round(lat * 10000) / 10000
  const rlon = Math.round(lon * 10000) / 10000
  const hh = Math.floor(acq_time / 100)
  const mm = acq_time % 100
  const minute = `${acq_date}T${String(hh).padStart(2,'0')}:${String(mm).padStart(2,'0')}:00Z`
  return `${fuente}|${instrument}|${satellite}|${minute}|${rlat}|${rlon}`
}

// --- Descarga CSV FIRMS (API key en el path) ---
async function fetchCSV(url: string) {
  const res = await fetch(url)
  if (!res.ok) {
    const t = await res.text().catch(() => '')
    throw new Error(`FIRMS fetch failed (${res.status}): ${t.slice(0,200)}`)
  }

  const text = await res.text()
  const lines = text.trim().split(/\r?\n/)
  if (!lines.length) return []

  // Header minificado ‚Üí lowercase, sin BOM
  const header = lines[0].replace(/^\ufeff/, '').trim()
  const cols = header.split(',').map(c => c.trim().toLowerCase())

  // Debug √∫til en runtime
  console.log('üß© [FIRMS] Headers:', cols)

  const unquote = (s: string) => (s != null ? s.replace(/^"(.*)"$/, '$1').trim() : '')
  const rows: Row[] = lines.slice(1).map(line => {
    const v = line.split(',').map(unquote)
    const o: Record<string, string> = {}
    for (let i = 0; i < cols.length; i++) o[cols[i]] = v[i] ?? ''
    return o
  })

  // Log sample para detectar cambios de esquema r√°pido
  if (rows.length) {
    const it = rows[0]
    console.log('üß™ [FIRMS] Primera fila (subset):', {
      lat: it.latitude ?? it.lat,
      lon: it.longitude ?? it.lon,
      date: it.acq_date ?? it.date,
      time: it.acq_time ?? it.time,
      product: it.product,
      instrument: it.instrument,
      satellite: it.satellite,
    })
  }

  return rows
}

async function fetchAllFirms(): Promise<Row[]> {
  const urls = buildFirmsUrls()
  console.log('üåç [FIRMS] URLs generadas:', urls)
  const batches = await Promise.all(urls.map(async u => {
    try {
      const csv = await fetchCSV(u)
      console.log(`üì¶ [FIRMS] ${csv.length} filas desde ${u.slice(0,80)}...`)
      return csv
    } catch (err: any) {
      console.error(`‚ùå [FIRMS] Error al descargar ${u.slice(0,80)}...`, err.message)
      return []
    }
  }))
  return batches.flat()
}

// --- Normalizaci√≥n de filas CSV a estructura interna ---
function normalize(items: Row[]) {
  return items
    .map(it => {
      const lat = toFloat(it.latitude ?? it.lat)
      const lon = toFloat(it.longitude ?? it.lon)

      const acq_date = String(it.acq_date ?? it.date ?? '').slice(0,10)
      const acq_time = toNum(it.acq_time ?? it.time ?? 0) // soporta "0454"

      const fuente = String(it.source ?? 'FIRMS')
      const instrument = String(
        it.instrument ?? it.sensor ?? (String(it.product ?? '').toLowerCase().includes('modis') ? 'MODIS' : 'VIIRS')
      )
      const satellite = String(it.satellite ?? it.sat ?? (it.product ?? ''))

      const daynight = it.daynight ? String(it.daynight) : null
      const brightness = it.brightness != null && it.brightness !== '' ? toFloat(it.brightness) : null
      const frp        = it.frp        != null && it.frp        !== '' ? toFloat(it.frp)        : null
      // En VIIRS confidence puede ser porcentaje o letra (n,l,h); aqu√≠ lo intentamos como n√∫mero
      const confidenceParsed = it.confidence != null && it.confidence !== '' ? toFloat(it.confidence) : null
      const confidence = Number.isFinite(confidenceParsed as any) ? confidenceParsed : null

      return {
        fuente,
        instrument,
        satellite,
        acq_date,
        acq_time,
        lat,
        lon,
        daynight,
        brightness,
        frp,
        confidence,
        raw: it
      }
    })
    .filter(x =>
      x.acq_date?.length === 10 &&
      Number.isFinite(x.acq_time) &&
      Number.isFinite(x.lat) &&
      Number.isFinite(x.lon)
    )
}

// --- UPSERT: inserta o actualiza si ya existe el hash_dedupe ---
async function upsertPuntos(norm: ReturnType<typeof normalize>) {
  if (!norm.length) return { insertados: 0, actualizados: 0, ignorados: 0, ids: [] as string[] }

  const repo = AppDataSource.getRepository(PuntoCalor)

  const vals = norm.map(n => {
  const geomExpr = `ST_SetSRID(ST_MakePoint(${n.lon}, ${n.lat}), 4326)`
    const hash = hashDedupe(n.fuente, n.instrument, n.satellite, n.acq_date, n.acq_time, n.lat, n.lon)
    return {
      fuente: n.fuente,
      instrument: n.instrument,
      satellite: n.satellite,
      version: null,
      acq_date: n.acq_date,
      acq_time: n.acq_time,
      daynight: n.daynight,
      // ‚ö†Ô∏è tu entity tipa NUMERIC como string|null ‚Üí mandamos string
      confidence: n.confidence == null ? null : String(n.confidence),
      frp:        n.frp        == null ? null : String(n.frp),
      brightness: n.brightness == null ? null : String(n.brightness),
      bright_ti4: null,
      bright_ti5: null,
      scan: null,
      track: null,
      geom: () => geomExpr,  // raw SQL
      region: null,
      hash_dedupe: hash
    }
  })

  const batch = Number.isFinite(env.FIRMS_BATCH_SIZE) ? env.FIRMS_BATCH_SIZE : 2000
  let insertados = 0
  let actualizados = 0
  const ids: string[] = []

  for (let i = 0; i < vals.length; i += batch) {
    const slice = vals.slice(i, i + batch)

    // Estimaci√≥n de existentes antes del UPSERT (para m√©tricas)
    const existed = await repo.createQueryBuilder('p')
      .select(['p.hash_dedupe'])
      .where('p.hash_dedupe IN (:...h)', { h: slice.map(s => s.hash_dedupe!) })
      .getMany()
    const existedSet = new Set(existed.map(e => e.hash_dedupe!))

    const r = await repo
      .createQueryBuilder()
      .insert()
      .values(slice)
      .onConflict(`(hash_dedupe) WHERE hash_dedupe IS NOT NULL DO UPDATE SET
          daynight       = EXCLUDED.daynight,
          confidence     = EXCLUDED.confidence,
          frp            = EXCLUDED.frp,
          brightness     = EXCLUDED.brightness,
          bright_ti4     = EXCLUDED.bright_ti4,
          bright_ti5     = EXCLUDED.bright_ti5,
          scan           = EXCLUDED.scan,
          track          = EXCLUDED.track,
          region         = EXCLUDED.region,
          actualizado_en = now()`)
      .returning(['punto_calor_uuid', 'hash_dedupe'])
      .execute()

    const ret = r.raw as Array<{ punto_calor_uuid: string; hash_dedupe: string }>
    ids.push(...ret.map(x => x.punto_calor_uuid))

    // M√©tricas: los que ya exist√≠an ‚Üí actualizados; resto ‚Üí insertados
    const sliceHashes = slice.map(s => s.hash_dedupe!)
    let preExisting = 0
    for (const h of sliceHashes) if (existedSet.has(h)) preExisting++

    actualizados += preExisting
    insertados   += Math.max(0, slice.length - preExisting)
  }

  return { insertados, actualizados, ignorados: 0, ids }
}

// --- Asociaci√≥n puntos ‚Üî incendios cercanos en espacio/tiempo ---
async function associateToIncendios(puntoIds: string[]) {
  if (!puntoIds.length) return { asociados: 0, porIncendio: {} as Record<string, number> }

  const radiusKm = RADIUS_KM
  const deltaH   = WINDOW_H
  const rMeters  = radiusKm * 1000

  const raw = await AppDataSource.query(
    `
    with pts as (
      select p.punto_calor_uuid, p.acq_date, p.acq_time, p.geom
      from puntos_calor p
      where p.punto_calor_uuid = ANY($1)
    ),
    pts_dt as (
      select punto_calor_uuid,
             to_timestamp(
               acq_date || ' ' ||
               lpad((acq_time/100)::int::text,2,'0') || ':' ||
               lpad((acq_time%100)::int::text,2,'0'),
               'YYYY-MM-DD HH24:MI'
             ) at time zone 'UTC' as acq_dt,
             geom
      from pts
    ),
    cand as (
      select i.incendio_uuid, i.creado_en, i.centroide as igeom
      from incendios i
      join estado_incendio e on e.estado_incendio_uuid = i.estado_incendio_uuid
      where i.eliminado_en is null
        and i.centroide is not null
        and e.codigo in ('pendiente','activo')
    ),
    pairs as (
      select
        p.punto_calor_uuid,
        c.incendio_uuid,
        ST_DistanceSphere(p.geom, c.igeom) as dist,
        EXTRACT(EPOCH FROM (p.acq_dt - c.creado_en))/60 as delta_min
      from pts_dt p
      join cand c
        on ST_DWithin(p.geom::geography, c.igeom::geography, $2)
      where abs(EXTRACT(EPOCH FROM (p.acq_dt - c.creado_en))) <= $3*3600
    ),
    pick as (
      select distinct on (punto_calor_uuid)
        punto_calor_uuid, incendio_uuid, dist, delta_min
      from pairs
      order by punto_calor_uuid, dist asc
    )
    select * from pick
    `,
    [puntoIds, rMeters, deltaH]
  )

  let asociados = 0
  const porIncendio: Record<string, number> = {}
  const repo = AppDataSource.getRepository(PuntoCalor)

  for (const row of raw) {
    const pcId = row.punto_calor_uuid
    const incId = row.incendio_uuid
    const existing = await repo.findOne({ where: { punto_calor_uuid: pcId }, relations: ['incendio'] })
    if (existing && !existing.incendio) {
      await repo.update({ punto_calor_uuid: pcId }, { incendio: { incendio_uuid: incId } as any })
      asociados += 1
      porIncendio[incId] = (porIncendio[incId] || 0) + 1
    }
  }

  return { asociados, porIncendio, regla: `R=${radiusKm}km,Œît=¬±${deltaH}h` }
}

// --- Orquestador principal ---
export async function runFirmsIngest() {
  const jobRepo = AppDataSource.getRepository(JobRun)
  const auditRepo = AppDataSource.getRepository(AuditoriaEventos)
  const job = jobRepo.create({ nombre_job: 'firms:ingest', inicio: new Date(), status: 'RUNNING' })
  await jobRepo.save(job)

  try {
    console.log('üöÄ [FIRMS] Iniciando ingesta manual...')
    const items = await fetchAllFirms()
    console.log(`üìä [FIRMS] Total filas brutas: ${items.length}`)

    const norm = normalize(items)
    console.log(`üìä [FIRMS] Normalizadas: ${norm.length}`)

    const up = await upsertPuntos(norm)
    console.log(`üíæ [FIRMS] Insertados: ${up.insertados}, Actualizados: ${up.actualizados}, Ignorados: ${up.ignorados}`)

    const asoc = await associateToIncendios(up.ids)
    console.log(`üîó [FIRMS] Asociados: ${asoc.asociados}`)

    job.insertados = up.insertados
    job.ignorados = up.ignorados
    ;(job as any).actualizados = up.actualizados // si tienes la columna, gu√°rdalo; si no, ignora esta l√≠nea
    job.asociados = asoc.asociados
    job.status = 'OK'
    job.fin = new Date()
    await jobRepo.save(job)

    return { ok: true, insertados: up.insertados, actualizados: up.actualizados, ignorados: up.ignorados, asociados: asoc.asociados }
  } catch (e: any) {
    console.error('‚ùå [FIRMS] Error general:', e)
    job.status = 'ERROR'
    job.fin = new Date()
    job.errores = { message: e?.message || String(e) }
    await jobRepo.save(job)
    throw e
  }
}
